{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News project \n",
    "### Data science course 2022/2023\n",
    "\n",
    "**Authors**:\n",
    " - Tove Eggert Olsen, kxd956\n",
    " - Isak Erkam Kilic, htp748 \n",
    " - Ellen Hørlyck Ebdrup, hxk874\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages\n",
    "Some of the package are not used in the final report, but was used during exploration of the data and when testing with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, r2_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import *\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import *\n",
    "\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing files\n",
    "\n",
    "You can find files including the cleaned data, saved models and raw data in the GoogleDrive: [Click here](https://drive.google.com/drive/folders/1IlzLLjC91VWXk47Z4oNbRCpK-oPjfYsV?usp=sharing)\n",
    "\n",
    "If you insert the files into the same folder as the notebook, you can run the code. Make sure not to run all cells at once, as some cells take a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe containing all websites and their labels\n",
    "websites_df = pd.read_csv('websites.csv')\n",
    "\n",
    "# A dataframe containing 568.360 data points after cleaning 2 million data points.\n",
    "df_600K_cleaned = pd.read_csv('600K_cleaned.csv', usecols=['domain', 'type', 'content', 'type_binary'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "The function sorting() is used to sort the data into a dataframe. Noise from the data is removed and labels are replaced with 0 and 1, where 1 denotes a fake news article.\n",
    "\n",
    "The function clean_text() is used to clean the text. It removes punctuation, insert, stopwords and stems the text. The function is used on the data efter it is sorted.\n",
    "\n",
    "The function process() calls sorting() and then clean_text() for a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_df(df):\n",
    "    df.dropna(axis=0, inplace=True) \n",
    "    df.drop(df[df['type'] == 'unknown'].index, inplace = True) \n",
    "    df.drop(df[df['type'] == 'rumor'].index, inplace = True) \n",
    "    df.drop_duplicates(subset=['content'], keep='first', inplace=True) \n",
    "\n",
    "    fake_group = ['fake','satire','bias','conspiracy','junksci','hate','unreliable']\n",
    "    df['type_binary'] = df['type'].isin(fake_group)\n",
    "    df['type_binary'] = df['type_binary'].astype(int) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('  ', '')\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'(\\´)|(\\`)|(\\')|(\\\")|(\\“)|(\\”)', '', text)\n",
    "    \n",
    "    replace = re.sub(\"http\\S+|www\\S+\", '<URL>', text)\n",
    "    replace = re.sub(r'\\S+@+\\S+\\.+\\S', 'EMAIL', replace)\n",
    "    replace = re.sub(r'\\S+\\.com\\S', 'URL', replace)\n",
    "    replace = re.sub(r'(\\d{4}/\\d{2}/\\d{2} \\d{2}\\:\\d{2}\\:\\d{2}\\.\\d)|(\\d{4}-\\d{2}-\\d{2} \\d{2}\\:\\d{2}\\:\\d{2}\\.\\d)', 'DATE', replace)\n",
    "    replace = re.sub(r'\\d{2}\\:\\d{2}\\:\\d{2}\\.\\d', 'TIME', replace)\n",
    "    replace = re.sub(r'\\d+,?\\.?\\d*\\.?\\d*', 'NUM', replace)\n",
    "    replace = re.sub(r'(\\-)|(\\—)', '', replace)\n",
    "    \n",
    "    nopunc = [char for char in replace if char not in string.punctuation] \n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    clean_words = [word for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "    cleaned = [stemmer.stem(word) for word in clean_words]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataframe):\n",
    "    df = sorting_df(dataframe)\n",
    "    df['content'] = df['content'].apply(clean_text)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model comparison\n",
    "\n",
    "In this section we explore different models on a subset of 10.000 data points  from our prosseced data. \n",
    "\n",
    "First we split the data into a training, validation and test set. We use the function train_test_split() from sklearn.model_selection. We use 80% of the data for training and 10% both for validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10k = pd.read_csv('600K_cleaned.csv', nrows=10000)\n",
    "df_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_10k\n",
    "X  = df['content']\n",
    "y = df['type_binary']\n",
    "\n",
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-train_ratio, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=0)\n",
    "\n",
    "print (\"x split into train, validation and test sets: \", X_train.shape, X_val.shape, X_test.shape)\n",
    "print (\"y split into train, validation and test sets: \", y_train.shape, y_val.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "models['Logistic Regression'] = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "# Support Vector Machines\n",
    "models['Support Vector Machines'] = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "# Decision Trees\n",
    "models['Decision Trees'] = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "# Random Forest\n",
    "models['Random Forest'] = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "models['K-Nearest Neighbor'] = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "models['Multi-Layer Perceptron'] = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MLPClassifier(verbose=True))])\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    predictions = models[key].predict(X_val)\n",
    "    \n",
    "    accuracy[key] = accuracy_score(predictions, y_val)\n",
    "    precision[key] = precision_score(predictions, y_val)\n",
    "    recall[key] = recall_score(predictions, y_val)\n",
    "\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "df_model['f1 score'] = 2 * (df_model['Precision'] * df_model['Recall']) / (df_model['Precision'] + df_model['Recall'])\n",
    "\n",
    "df_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a larger dataset\n",
    "From processing the 2 million data points, we ended up with a sample of around 600.000 data points.\n",
    "\n",
    "### Splitting data \n",
    "Define the dataframe in which the data is stored in the variable \"df\". The data is split into a training set (80 %), a validation set (10 %) and a test set (10 %). The training set is used to train the model and the validation set is used to tune the hyperparameters and test the models. We will first be using the test set ind the end of the project to test the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_600K_cleaned\n",
    "\n",
    "X  = df['content']\n",
    "y = df['type_binary']\n",
    "\n",
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-train_ratio, random_state=0)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=0)\n",
    "\n",
    "print (\"X split into train, validation and test sets: \", X_train.shape, X_val.shape, X_test.shape)\n",
    "print (\"y split into train, validation and test sets: \", y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "### Using Logistic regression, TfidfVec\n",
    "\n",
    "We will visualize the result from the model using a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, n_jobs=-1, class_weight={0: 1, 1: 1}, random_state=0))\n",
    "])\n",
    "\n",
    "logreg_trained = pipe.fit(X_train,y_train)\n",
    "predictions = pipe.predict(X_val)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "report = classification_report(y_val, predictions)\n",
    "print (report)\n",
    "\n",
    "# Saving the trained model as a file \n",
    "dump(logreg_trained, 'LogReg_600K.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced model\n",
    "### MLP Classifier, Neural Network \n",
    "\n",
    "We will visualize the result from model using a confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes = (5, 2), random_state = 0)\n",
    "\n",
    "clf_pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MLP)])\n",
    "\n",
    "mlp_trained = clf_pipe.fit(X_train, y_train)\n",
    "y_pred_MLP = clf_pipe.predict(X_val)\n",
    "\n",
    "report = classification_report(y_val, y_pred_MLP)\n",
    "print (report)\n",
    "\n",
    "TN_MLP, FP_MLP, FN_MLP, TP_MLP = confusion_matrix(y_val, y_pred_MLP).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP_MLP)\n",
    "print('False Positive(FP) = ', FP_MLP)\n",
    "print('True Negative(TN)  = ', TN_MLP)\n",
    "print('False Negative(FN) = ', FN_MLP)\n",
    "\n",
    "TP_MLP_pro = TP_MLP/(TP_MLP+FP_MLP+FN_MLP+TN_MLP)*100\n",
    "FP_MLP_pro = FP_MLP/(TP_MLP+FP_MLP+FN_MLP+TN_MLP)*100\n",
    "TN_MLP_pro = TN_MLP/(TP_MLP+FP_MLP+FN_MLP+TN_MLP)*100\n",
    "FN_MLP_pro = FN_MLP/(TP_MLP+FP_MLP+FN_MLP+TN_MLP)*100\n",
    "\n",
    "# Saving the trained model as a file \n",
    "dump(mlp_trained, 'MLP_600K.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on unseen data\n",
    "### Using the LIAR dataset\n",
    "\n",
    "We will start by importing the data and processeing it. We will then use the simple and advance model to predict the labels of the data. <br>\n",
    "Make sure to have downloadet the file \"LogReg_600K.joblib\" and \"MLP_600K.joblib\" from the GoogleDrive and placed it in the same folder as the notebook.\n",
    "We will use these models to predict the labels of the data.\n",
    "\n",
    "We will visualize the result from the model using a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['json','type','content','keywords','idk','idk2','state','politics','num1','num2','num3','num4','num5','category']\n",
    "df_liar_train = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "df_liar_test = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)\n",
    "df_liar_val = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "# Concat LIAR train, test, and val files into one dataframe\n",
    "df_LIAR = pd.concat([df_liar_train, df_liar_test, df_liar_val], ignore_index=True)\n",
    "\n",
    "# Drop unused columns\n",
    "df_LIAR = df_LIAR.drop(['json','keywords','idk','idk2','state','politics','num1','num2','num3','num4','num5','category'],inplace=False, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_liar(df):\n",
    "    liar_fake_group = ['false','pants-fire', 'barely-true','half-true']\n",
    "    df['type_binary'] = df['type'].isin(liar_fake_group)\n",
    "    df['type_binary'] = df['type_binary'].astype(int) # define types\n",
    "    return df\n",
    "\n",
    "# Preprocess dataframe\n",
    "def preprocess_liar(df):\n",
    "    df = sorting_liar(df) \n",
    "    df['content'] = df['content'].apply(clean_text) \n",
    "    df['content'] = df['content'].astype(str) \n",
    "    return df\n",
    "\n",
    "\n",
    "df_LIAR = preprocess_liar(df_LIAR)\n",
    "\n",
    "X_liar = df_LIAR['content']\n",
    "y_liar = df_LIAR['type_binary']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Logistic Regression on LIAR dataset \n",
    "logreg_model = load('LogReg_600K.joblib')\n",
    "predictions = logreg_model.predict(X_liar)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_liar, predictions).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "report_dict_LR_liar = classification_report(y_liar, predictions, output_dict=True) # save classification report as a dictionary\n",
    "\n",
    "report = classification_report(y_liar, predictions, output_dict=False)\n",
    "print (report)\n",
    "\n",
    "df_logreg_LIAR = pd.DataFrame({'lab':['TP', 'FP', 'TN', 'FN'], 'val':[(TP/len(y_liar)*100), FP/len(y_val)*100, TN/len(y_val)*100, FN/len(y_val)*100]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with the advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the MLP model on the LIAR dataset \n",
    "mlp_model = load('MLP_600K.joblib')\n",
    "\n",
    "predictions = mlp_model.predict(X_liar)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_liar, predictions).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "report_dict_MLP_liar = classification_report(y_liar, predictions, output_dict=True) # save classification report as a dictionary\n",
    "\n",
    "report = classification_report(y_liar, predictions)\n",
    "print (report)\n",
    "\n",
    "df_MLP_LIAR = pd.DataFrame({'lab':['TP', 'FP', 'TN', 'FN'], 'val':[(TP/len(y_liar)*100), FP/len(y_val)*100, TN/len(y_val)*100, FN/len(y_val)*100]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5752aa9ab330d3759c83a1b34e6976ab41b98e9e7a9be5fc074dbcab196bea16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
